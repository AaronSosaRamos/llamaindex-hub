{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a65d3850-3ddb-4db3-87fe-fa7d92e6c55b",
      "metadata": {
        "id": "a65d3850-3ddb-4db3-87fe-fa7d92e6c55b"
      },
      "source": [
        "# Patient Case Summary Workflow\n",
        "\n",
        "## Made by: Wilfredo Aaron Sosa Ramos\n",
        "Resource: https://github.com/run-llama/llamacloud-demo/blob/main/examples/document_workflows/patient_case_summary/patient_case_summary.ipynb\n",
        "\n",
        "This tutorial shows you how to build an agentic workflow that can extract key details from a given patient, check clinical guidelines to see whether the patient's status meets recommended care standards, and then produce a human-readable case summary that a clinician can review.\n",
        "\n",
        "![](https://github.com/run-llama/llamacloud-demo/blob/main/examples/document_workflows/patient_case_summary/patient_case_summary.png?raw=1)\n",
        "\n",
        "We use [Synthea](https://github.com/synthetichealth/synthea) to generate synthetic patient data, which contains a comprehensive set of information surrounding the patient. This includes, among other attributes, active patient conditions, encounters, and medications.\n",
        "\n",
        "Given a sample patient, we extract out the relevant information, and use it to retrieve relevant medical guidelines that provide recommendations on continued treatment, and present it to a clinician."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "87c5f0d7-c884-475a-88ff-4b7057bb91a6",
      "metadata": {
        "id": "87c5f0d7-c884-475a-88ff-4b7057bb91a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "21ee9690-f1a5-4536-99ed-e81c8382528e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.10.68)\n",
            "Requirement already satisfied: llama-index-indices-llama-cloud in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Requirement already satisfied: llama-cloud in /usr/local/lib/python3.10/dist-packages (0.1.6)\n",
            "Requirement already satisfied: llama-parse in /usr/local/lib/python3.10/dist-packages (0.4.9)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.9)\n",
            "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.13)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.68 (from llama-index)\n",
            "  Using cached llama_index_core-0.10.68.post1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.11)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.7)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.9.48.post4)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.27 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.31)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.9)\n",
            "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.7)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.3)\n",
            "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.33)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.6)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.9 in /usr/local/lib/python3.10/dist-packages (from llama-index-indices-llama-cloud) (0.1.19)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cloud) (0.27.2)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llama-cloud) (2.10.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->llama-cloud) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->llama-cloud) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->llama-cloud) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->llama-cloud) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->llama-cloud) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.20.0->llama-cloud) (0.14.0)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.57.4)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.68->llama-index) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (2024.10.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (3.4.2)\n",
            "Requirement already satisfied: nltk!=3.9,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (2.2.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (11.0.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.68->llama-index) (1.17.0)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.3.1)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud) (2.27.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.68->llama-index) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.68->llama-index) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.68->llama-index) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.68->llama-index) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.68->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.68->llama-index) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.68->llama-index) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.68->llama-index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.68->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.68->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.68->llama-index) (2024.9.11)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (0.8.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->llama-cloud) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.68->llama-index) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.68->llama-index) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.68->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.68->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.68->llama-index) (3.23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.68->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.68->llama-index) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.68->llama-index) (2024.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.68->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.68->llama-index) (1.17.0)\n",
            "Using cached llama_index_core-0.10.68.post1-py3-none-any.whl (1.6 MB)\n",
            "Installing collected packages: llama-index-core\n",
            "  Attempting uninstall: llama-index-core\n",
            "    Found existing installation: llama-index-core 0.12.5\n",
            "    Uninstalling llama-index-core-0.12.5:\n",
            "      Successfully uninstalled llama-index-core-0.12.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llama-index-utils-workflow 0.3.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed llama-index-core-0.10.68.post1\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index llama-index-indices-llama-cloud llama-cloud llama-parse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om0UG7RTqQ9d",
        "outputId": "a8e5f450-62e6-4d91-88d5-14b11e03ee01"
      },
      "id": "Om0UG7RTqQ9d",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade llama-index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwzPpGiy2YAk",
        "outputId": "9fdac6de-8dce-4a36-f42d-09dde5580b9a"
      },
      "id": "CwzPpGiy2YAk",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.12.5)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.5 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.12.5)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.6.3)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.9.48.post4)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.10)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.1)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.57.4)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.5->llama-index) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (2.10.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.5->llama-index) (1.17.0)\n",
            "Requirement already satisfied: llama-cloud>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.2.2)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.1.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.5.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (2024.9.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama-index) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama-index) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama-index) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama-index) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama-index) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama-index) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.5->llama-index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.5->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.5->llama-index) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.5->llama-index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.5->llama-index) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.5->llama-index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.5->llama-index) (0.14.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.5->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.5->llama-index) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.5->llama-index) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.5->llama-index) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.5->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.5->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.5->llama-index) (3.23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.5->llama-index) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.5->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install httpx=='0.27.2'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2rnUMTUggG7",
        "outputId": "7bed3fc3-856a-4831-e797-012597b8c9d3"
      },
      "id": "c2rnUMTUggG7",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: httpx==0.27.2 in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx==0.27.2) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx==0.27.2) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "aDtDk0pJfzbT"
      },
      "id": "aDtDk0pJfzbT",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d76541e7-65d3-4c70-afcd-49658bc00954",
      "metadata": {
        "id": "d76541e7-65d3-4c70-afcd-49658bc00954"
      },
      "source": [
        "## Setup\n",
        "\n",
        "We define code snippets which will parse a patient bundle and extract out relevant fields of interest, including:\n",
        "1. Patient demographics\n",
        "2. Condition\n",
        "3. Medication request\n",
        "4. Observation (vital signs)\n",
        "5. Immunization & Procedures\n",
        "\n",
        "\n",
        "We also setup an index for relevant clinical guidelines (e.g. ADA for diabetes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "89fc744f-04fa-4e07-a14e-93083c65af62",
      "metadata": {
        "id": "89fc744f-04fa-4e07-a14e-93083c65af62"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class ConditionInfo(BaseModel):\n",
        "    code: str\n",
        "    display: str\n",
        "    clinical_status: str\n",
        "\n",
        "class EncounterInfo(BaseModel):\n",
        "    date: str = Field(..., description=\"Date of the encounter.\")\n",
        "    reason_display: Optional[str] = Field(None, description=\"Reason for the encounter.\")\n",
        "    type_display: Optional[str] = Field(None, description=\"Type or class of the encounter.\")\n",
        "\n",
        "class MedicationInfo(BaseModel):\n",
        "    name: str = Field(..., description=\"Name of the medication.\")\n",
        "    start_date: Optional[str] = Field(None, description=\"When the medication was prescribed.\")\n",
        "    instructions: Optional[str] = Field(None, description=\"Dosage instructions.\")\n",
        "\n",
        "class PatientInfo(BaseModel):\n",
        "    given_name: str\n",
        "    family_name: str\n",
        "    birth_date: str\n",
        "    gender: str\n",
        "    conditions: List[ConditionInfo] = Field(default_factory=list)\n",
        "    recent_encounters: List[EncounterInfo] = Field(default_factory=list, description=\"A few recent encounters.\")\n",
        "    current_medications: List[MedicationInfo] = Field(default_factory=list, description=\"Current active medications.\")\n",
        "\n",
        "    @property\n",
        "    def demographic_str(self) -> str:\n",
        "        \"\"\"Get demographics string.\"\"\"\n",
        "        return f\"\"\"\\\n",
        "Given name: {self.given_name}\n",
        "Family name: {self.family_name}\n",
        "Birth date: {self.birth_date}\n",
        "Gender: {self.gender}\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bec87b1f-74e5-41e6-b482-ce077aeddb7e",
      "metadata": {
        "id": "bec87b1f-74e5-41e6-b482-ce077aeddb7e"
      },
      "outputs": [],
      "source": [
        "from datetime import (\n",
        "    datetime,\n",
        "    date\n",
        ")\n",
        "import json\n",
        "\n",
        "def parse_synthea_patient(file_path: str, filter_active: bool = True) -> PatientInfo:\n",
        "    # Load the Synthea-generated FHIR Bundle\n",
        "    with open(file_path, \"r\") as f:\n",
        "        bundle = json.load(f)\n",
        "\n",
        "    patient_resource = None\n",
        "    conditions = []\n",
        "    encounters = []\n",
        "    medication_requests = []\n",
        "\n",
        "    for entry in bundle.get(\"entry\", []):\n",
        "        resource = entry.get(\"resource\", {})\n",
        "        resource_type = resource.get(\"resourceType\")\n",
        "\n",
        "        if resource_type == \"Patient\":\n",
        "            patient_resource = resource\n",
        "        elif resource_type == \"Condition\":\n",
        "            conditions.append(resource)\n",
        "        elif resource_type == \"Encounter\":\n",
        "            encounters.append(resource)\n",
        "        elif resource_type == \"MedicationRequest\":\n",
        "            medication_requests.append(resource)\n",
        "\n",
        "    if not patient_resource:\n",
        "        raise ValueError(\"No Patient resource found in the provided file.\")\n",
        "\n",
        "    # Extract patient demographics\n",
        "    name_entry = patient_resource.get(\"name\", [{}])[0]\n",
        "    given_name = name_entry.get(\"given\", [\"\"])[0]\n",
        "    family_name = name_entry.get(\"family\", \"\")\n",
        "    birth_date = patient_resource.get(\"birthDate\", \"\")\n",
        "    gender = patient_resource.get(\"gender\", \"\")\n",
        "\n",
        "    # Define excluded conditions\n",
        "    excluded_conditions = {\"Medication review due (situation)\", \"Risk activity involvement (finding)\"}\n",
        "    condition_info_list = []\n",
        "    for c in conditions:\n",
        "        code_info = c.get(\"code\", {}).get(\"coding\", [{}])[0]\n",
        "        condition_code = code_info.get(\"code\", \"Unknown\")\n",
        "        condition_display = code_info.get(\"display\", \"Unknown\")\n",
        "        clinical_status = (\n",
        "            c.get(\"clinicalStatus\", {})\n",
        "             .get(\"coding\", [{}])[0]\n",
        "             .get(\"code\", \"unknown\")\n",
        "        )\n",
        "\n",
        "        # Check exclusion and active filters\n",
        "        if condition_display not in excluded_conditions:\n",
        "            if filter_active:\n",
        "                if clinical_status == \"active\":\n",
        "                    condition_info_list.append(\n",
        "                        ConditionInfo(\n",
        "                            code=condition_code,\n",
        "                            display=condition_display,\n",
        "                            clinical_status=clinical_status\n",
        "                        )\n",
        "                    )\n",
        "            else:\n",
        "                # Include conditions regardless of their status if filter_active is False\n",
        "                condition_info_list.append(\n",
        "                    ConditionInfo(\n",
        "                        code=condition_code,\n",
        "                        display=condition_display,\n",
        "                        clinical_status=clinical_status\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    # Parse encounters\n",
        "    def get_encounter_date(enc):\n",
        "        period = enc.get(\"period\", {})\n",
        "        start = period.get(\"start\")\n",
        "        return datetime.fromisoformat(start).date().isoformat() if start else date.min\n",
        "\n",
        "    encounters_sorted = sorted(encounters, key=get_encounter_date)\n",
        "    recent_encounters = encounters_sorted[-3:] if len(encounters_sorted) > 3 else encounters_sorted\n",
        "\n",
        "    encounter_info_list = []\n",
        "    for e in recent_encounters:\n",
        "        period = e.get(\"period\", {})\n",
        "        start_date = period.get(\"start\", \"\")\n",
        "        reason = e.get(\"reasonCode\", [{}])[0].get(\"coding\", [{}])[0].get(\"display\", None)\n",
        "        etype = e.get(\"type\", [{}])[0].get(\"coding\", [{}])[0].get(\"display\", None)\n",
        "        encounter_info_list.append(\n",
        "            EncounterInfo(\n",
        "                date=start_date,\n",
        "                reason_display=reason,\n",
        "                type_display=etype\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Parse medications\n",
        "    medication_info_list = []\n",
        "    for m in medication_requests:\n",
        "        status = m.get(\"status\")\n",
        "        if status == \"active\":\n",
        "            med_code = m.get(\"medicationCodeableConcept\", {}).get(\"coding\", [{}])[0]\n",
        "            med_name = med_code.get(\"display\", \"Unknown Medication\")\n",
        "            authored = m.get(\"authoredOn\", None)\n",
        "            dosage_instruction = m.get(\"dosageInstruction\", [{}])[0].get(\"text\", None)\n",
        "            medication_info_list.append(\n",
        "                MedicationInfo(\n",
        "                    name=med_name,\n",
        "                    start_date=authored,\n",
        "                    instructions=dosage_instruction\n",
        "                )\n",
        "            )\n",
        "\n",
        "    patient_info = PatientInfo(\n",
        "        given_name=given_name,\n",
        "        family_name=family_name,\n",
        "        birth_date=birth_date,\n",
        "        gender=gender,\n",
        "        conditions=condition_info_list,\n",
        "        recent_encounters=encounter_info_list,\n",
        "        current_medications=medication_info_list\n",
        "    )\n",
        "\n",
        "    return patient_info\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f1f9ee2f-0c0f-4d63-aa8b-c56085f76119",
      "metadata": {
        "scrolled": true,
        "id": "f1f9ee2f-0c0f-4d63-aa8b-c56085f76119",
        "outputId": "e104c9cd-7599-4ed8-c5a8-8dc8fd155dbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'given_name': 'Almeta56',\n",
              " 'family_name': 'Buckridge80',\n",
              " 'birth_date': '2010-12-31',\n",
              " 'gender': 'female',\n",
              " 'conditions': [{'code': '24079001',\n",
              "   'display': 'Atopic dermatitis (disorder)',\n",
              "   'clinical_status': 'active'},\n",
              "  {'code': '233678006',\n",
              "   'display': 'Childhood asthma (disorder)',\n",
              "   'clinical_status': 'active'}],\n",
              " 'recent_encounters': [{'date': '2024-01-26T01:38:45-08:00',\n",
              "   'reason_display': None,\n",
              "   'type_display': 'Well child visit (procedure)'},\n",
              "  {'date': '2024-02-09T01:38:45-08:00',\n",
              "   'reason_display': 'Patient referral for dental care (procedure)',\n",
              "   'type_display': 'Encounter for check up (procedure)'},\n",
              "  {'date': '2024-10-05T21:38:45-07:00',\n",
              "   'reason_display': 'Childhood asthma (disorder)',\n",
              "   'type_display': 'Asthma follow-up (regime/therapy)'}],\n",
              " 'current_medications': [{'name': 'Loratadine 5 MG Chewable Tablet',\n",
              "   'start_date': '2011-07-25T11:14:11-07:00',\n",
              "   'instructions': 'Take as needed.'},\n",
              "  {'name': 'NDA020800 0.3 ML Epinephrine 1 MG/ML Auto-Injector',\n",
              "   'start_date': '2011-07-25T11:14:11-07:00',\n",
              "   'instructions': 'Take as needed.'},\n",
              "  {'name': '120 ACTUAT fluticasone propionate 0.044 MG/ACTUAT Metered Dose Inhaler [Flovent]',\n",
              "   'start_date': '2024-01-26T01:38:45-08:00',\n",
              "   'instructions': 'Take as needed.'},\n",
              "  {'name': 'albuterol 0.417 MG/ML Inhalation Solution',\n",
              "   'start_date': '2024-01-26T01:38:45-08:00',\n",
              "   'instructions': 'Take as needed.'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Example Usage\n",
        "patient_info = parse_synthea_patient(\"data/almeta_buckridge.json\")\n",
        "patient_info.model_dump()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27a1399a-8280-42f6-9355-a046cd1828d4",
      "metadata": {
        "id": "27a1399a-8280-42f6-9355-a046cd1828d4"
      },
      "source": [
        "### Map Conditions to Encounters/Medications\n",
        "\n",
        "We now use an LLM to dynamically transform the existing JSON into a new structured output (a \"ConditionBundle\") where we map each condition to its associated encounters/medications. We rely on the LLM's prior medical knowledge to do this transformation.\n",
        "\n",
        "This transformation allows us to then consult the relevant guidelines for each condition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a3b6ede9-af91-4cec-8f1c-54913722eb85",
      "metadata": {
        "id": "a3b6ede9-af91-4cec-8f1c-54913722eb85"
      },
      "outputs": [],
      "source": [
        "class ConditionBundle(BaseModel):\n",
        "    condition: ConditionInfo\n",
        "    encounters: List[EncounterInfo] = Field(default_factory=list)\n",
        "    medications: List[MedicationInfo] = Field(default_factory=list)\n",
        "\n",
        "class ConditionBundles(BaseModel):\n",
        "    bundles: List[ConditionBundle]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "756xfHubdPAO"
      },
      "id": "756xfHubdPAO",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "25fb1368-73bd-43ae-a3df-69b22410983f",
      "metadata": {
        "id": "25fb1368-73bd-43ae-a3df-69b22410983f"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.llms import LLM\n",
        "from llama_index.core.prompts import ChatPromptTemplate\n",
        "\n",
        "CONDITION_BUNDLE_PROMPT = \"\"\"\\\n",
        "You are an assistant that takes a patient's summarized clinical data and associates each active condition with any relevant recent encounters and current medications.\n",
        "\n",
        "**Steps to follow:**\n",
        "1. Review the patient's demographics, conditions, recent encounters, and current medications.\n",
        "2. For each condition in 'conditions':\n",
        "   - Determine which of the 'recent_encounters' are relevant. An encounter is relevant if:\n",
        "     - The 'reason_display' or 'type_display' of the encounter mentions or is closely related to the condition.\n",
        "     - Consider synonyms or partial matches. For example, for \"Childhood asthma (disorder)\", any encounter mentioning \"asthma\" or \"asthma follow-up\" is relevant.\n",
        "   - Determine which of the 'current_medications' are relevant. A medication is relevant if:\n",
        "     - The medication 'name' or 'instructions' are clearly related to managing that condition. For example, inhalers or corticosteroids for asthma, topical creams for dermatitis.\n",
        "     - Consider partial matches. For \"Atopic dermatitis (disorder)\", a medication used for allergic conditions or skin inflammations could be relevant.\n",
        "3. Ignore patient demographics for relevance determination; they are just context.\n",
        "4. Return the final output strictly as a JSON object following the schema (provided as a tool call).\n",
        "   Do not include extra commentary outside the JSON.\n",
        "\n",
        "**Patient Data**:\n",
        "{patient_info}\n",
        "\"\"\"\n",
        "\n",
        "async def create_condition_bundles(\n",
        "    patient_data: PatientInfo, llm: Optional[LLM] = None\n",
        ") :\n",
        "    llm = llm or OpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "    # we will dump the entire patient info into an LLM and have it figure out the relevant encounters/medications\n",
        "    # associated with each condition\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"user\", CONDITION_BUNDLE_PROMPT)\n",
        "    ])\n",
        "    condition_bundles = await llm.astructured_predict(\n",
        "        ConditionBundles,\n",
        "        prompt,\n",
        "        patient_info=patient_data.json()\n",
        "    )\n",
        "\n",
        "    return condition_bundles"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aec6dbbd-fc9a-4f16-8e7a-047eb89b08fc",
      "metadata": {
        "id": "aec6dbbd-fc9a-4f16-8e7a-047eb89b08fc"
      },
      "source": [
        "Let's run a sample (we will plug this into a full workflow later)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0f946b2a-5e52-4486-8732-1e90e724b0f5",
      "metadata": {
        "id": "0f946b2a-5e52-4486-8732-1e90e724b0f5",
        "outputId": "4a39234f-4426-43be-a8c1-f797f0db2047",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-0bc53d930ffb>:38: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  patient_info=patient_data.json()\n"
          ]
        }
      ],
      "source": [
        "condition_bundles = await create_condition_bundles(patient_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "condition_bundles.model_dump()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izIxoyx7gCpl",
        "outputId": "6869c161-4d7b-4c74-d87a-b2d50392bd21"
      },
      "id": "izIxoyx7gCpl",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bundles': [{'condition': {'code': '24079001',\n",
              "    'display': 'Atopic dermatitis (disorder)',\n",
              "    'clinical_status': 'active'},\n",
              "   'encounters': [],\n",
              "   'medications': []},\n",
              "  {'condition': {'code': '233678006',\n",
              "    'display': 'Childhood asthma (disorder)',\n",
              "    'clinical_status': 'active'},\n",
              "   'encounters': [{'date': '2024-10-05T21:38:45-07:00',\n",
              "     'reason_display': 'Childhood asthma (disorder)',\n",
              "     'type_display': 'Asthma follow-up (regime/therapy)'}],\n",
              "   'medications': [{'name': '120 ACTUAT fluticasone propionate 0.044 MG/ACTUAT Metered Dose Inhaler [Flovent]',\n",
              "     'start_date': '2024-01-26T01:38:45-08:00',\n",
              "     'instructions': 'Take as needed.'},\n",
              "    {'name': 'albuterol 0.417 MG/ML Inhalation Solution',\n",
              "     'start_date': '2024-01-26T01:38:45-08:00',\n",
              "     'instructions': 'Take as needed.'}]}]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e01c7a8f-25f9-4f3b-b040-ee15d34826f6",
      "metadata": {
        "id": "e01c7a8f-25f9-4f3b-b040-ee15d34826f6"
      },
      "source": [
        "### Setup Index\n",
        "\n",
        "We've setup the right extraction flow over the patient record. The next step is to setup an index that contains a set of relevant guidelines which we will match against each condition of the patient. This will help us generate a more useful and comprehensive case summary.\n",
        "\n",
        "Here we use LlamaCloud: https://cloud.llamaindex.ai/. If you don't have access yet, you're always welcome to use our open-source VectorStoreIndex."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56212b49-964a-49b8-beac-f55abf0415c5",
      "metadata": {
        "id": "56212b49-964a-49b8-beac-f55abf0415c5"
      },
      "source": [
        "We use the following guidelines as datapoints:\n",
        "\n",
        "- [\"Guidelines of care for the management of atopic dermatitis in adults with phototherapy and systemic therapies\"](https://www.jaad.org/action/showPdf?pii=S0190-9622%2823%2902878-5) (from JAAD)\n",
        "- [\"2020 Focused Updates to the Asthma Management Guidelines\"](https://www.nhlbi.nih.gov/resources/2020-focused-updates-asthma-management-guidelines) (from NHLBI)\n",
        "\n",
        "Download the PDFs, and either upload them to LlamaCloud or index them through `VectorStoreIndex.from_documents`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade llama-index-core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWln3Hy-iMEA",
        "outputId": "38d266f9-0688-430b-9b2e-aaeac62334f4"
      },
      "id": "KWln3Hy-iMEA",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index-core in /usr/local/lib/python3.10/dist-packages (0.12.5)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (2.10.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.18.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8.0->llama-index-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8.0->llama-index-core) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core) (3.23.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core) (0.14.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core) (24.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import llama_index.core\n",
        "print (llama_index.core.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSqAVnW4pU4X",
        "outputId": "6246a875-c3bc-4afc-ed91-fb0e21d99a3b"
      },
      "id": "fSqAVnW4pU4X",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.workflow import (\n",
        "    Context,\n",
        ")\n",
        "\n",
        "print(dir(Context))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOSsV3-R1tnl",
        "outputId": "51d4f348-4fa6-489b-dd56-1e017c72dd14"
      },
      "id": "BOSsV3-R1tnl",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_deserialize_globals', '_deserialize_queue', '_serialize_globals', '_serialize_queue', 'collect_events', 'data', 'from_dict', 'get', 'get_result', 'lock', 'mark_in_progress', 'remove_from_in_progress', 'send_event', 'session', 'set', 'streaming_queue', 'to_dict', 'write_event_to_stream']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "def download_pdf(url_or_list, save_path=\"/content/pdfs\"):\n",
        "    \"\"\"\n",
        "    Download PDF files from a URL or a list of URLs and store them in the specified directory.\n",
        "\n",
        "    :param url_or_list: str or list, URL or list of URLs of the PDF files.\n",
        "    :param save_path: str, path where the files will be stored (default is /content).\n",
        "    :return: list, paths of the successfully downloaded files.\n",
        "    \"\"\"\n",
        "    # Ensure the save directory exists\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "\n",
        "    # Handle single URL or list of URLs\n",
        "    if isinstance(url_or_list, str):\n",
        "        url_or_list = [url_or_list]\n",
        "\n",
        "    downloaded_files = []\n",
        "\n",
        "    for url in url_or_list:\n",
        "        try:\n",
        "            # Perform the GET request to download the file\n",
        "            response = requests.get(url, stream=True)\n",
        "            response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "\n",
        "            # Check if the Content-Type is PDF\n",
        "            if \"application/pdf\" not in response.headers.get(\"Content-Type\", \"\"):\n",
        "                raise ValueError(f\"The URL does not point to a valid PDF file: {url}\")\n",
        "\n",
        "            # Extract the file name from the URL or use a default name\n",
        "            file_name = url.split(\"/\")[-1] or \"downloaded_file.pdf\"\n",
        "\n",
        "            # Ensure the file name ends with .pdf\n",
        "            if not file_name.endswith(\".pdf\"):\n",
        "                file_name += \".pdf\"\n",
        "\n",
        "            # Full path where the file will be saved\n",
        "            file_path = os.path.join(save_path, file_name)\n",
        "\n",
        "            # Write the file content to disk\n",
        "            with open(file_path, \"wb\") as pdf_file:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    pdf_file.write(chunk)\n",
        "\n",
        "            print(f\"File downloaded successfully: {file_path}\")\n",
        "            downloaded_files.append(file_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading the file from {url}: {e}\")\n",
        "\n",
        "    return downloaded_files\n",
        "\n",
        "urls = [\"https://aaiba.org.ar/gacetillas/2024/09/guia.pdf\", \"https://www.nhlbi.nih.gov/sites/default/files/publications/AsthmaManagementGuidelinesReport-2-4-21.pdf\"]\n",
        "download_pdf(urls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4hu60FXiohG",
        "outputId": "7b29d18d-c146-4c61-bb04-32cc644a5890"
      },
      "id": "r4hu60FXiohG",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded successfully: /content/pdfs/guia.pdf\n",
            "File downloaded successfully: /content/pdfs/AsthmaManagementGuidelinesReport-2-4-21.pdf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/pdfs/guia.pdf',\n",
              " '/content/pdfs/AsthmaManagementGuidelinesReport-2-4-21.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "# Load documents and build index\n",
        "documents = SimpleDirectoryReader(\n",
        "    \"/content/pdfs\"\n",
        ").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "id": "bblDwst7ii6Y"
      },
      "id": "bblDwst7ii6Y",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = index.as_retriever(similarity_top_k=3)"
      ],
      "metadata": {
        "id": "kHEyox8ukQvd"
      },
      "id": "kHEyox8ukQvd",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07ccec03-9aaf-42c7-99e1-f7187328548b",
      "metadata": {
        "id": "07ccec03-9aaf-42c7-99e1-f7187328548b"
      },
      "outputs": [],
      "source": [
        "#from llama_index.indices.managed.llama_cloud import LlamaCloudIndex\n",
        "\n",
        "#index = LlamaCloudIndex(\n",
        "#  name=\"medical_guidelines_0\",\n",
        "#  project_name=\"llamacloud_demo\",\n",
        "#  organization_id=\"cdcb3478-1348-492e-8aa0-25f47d1a3902\",\n",
        "  # api_key=\"llx-...\"\n",
        "#)\n",
        "\n",
        "\n",
        "#retriever = index.as_retriever(similarity_top_k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e36b38a-23cf-4dc5-bc64-49cea9467c16",
      "metadata": {
        "id": "2e36b38a-23cf-4dc5-bc64-49cea9467c16"
      },
      "source": [
        "### Define Guideline Recommendation Schema\n",
        "\n",
        "Given a condition (and associated encounters/medications), define an output schema that represents the matched guideline.\n",
        "\n",
        "We need to make sure we ask the right questions in order to retrieve the relevant guidelines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b6496ab9-e70a-4203-8411-fd7c167ee054",
      "metadata": {
        "id": "b6496ab9-e70a-4203-8411-fd7c167ee054"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class GuidelineQueries(BaseModel):\n",
        "    \"\"\"Represents a set of recommended queries to retrieve guideline sections relevant to the patient's conditions.\"\"\"\n",
        "    queries: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"A list of query strings that can be used to search a vector index of medical guidelines.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "24acdc84-9da0-4339-9c8e-fb9929d00286",
      "metadata": {
        "id": "24acdc84-9da0-4339-9c8e-fb9929d00286"
      },
      "outputs": [],
      "source": [
        "class GuidelineRecommendation(BaseModel):\n",
        "    guideline_source: str = Field(..., description=\"The origin of the guideline (e.g., 'NHLBI Asthma Guidelines').\")\n",
        "    recommendation_summary: str = Field(..., description=\"A concise summary of the relevant recommendation.\")\n",
        "    reference_section: Optional[str] = Field(None, description=\"Specific section or reference in the guideline.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15e1805c-a9ad-433c-8f22-a005de3fe0ab",
      "metadata": {
        "id": "15e1805c-a9ad-433c-8f22-a005de3fe0ab"
      },
      "source": [
        "### Define Final Output Schema\n",
        "\n",
        "This is the schema for the final case summary. It contains the patient's basic demographic info, conditions, and also matched guideline recommendations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b9f275f4-66cc-4950-93f7-47da98d14e96",
      "metadata": {
        "id": "b9f275f4-66cc-4950-93f7-47da98d14e96"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, List\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class ConditionSummary(BaseModel):\n",
        "    condition_display: str = Field(..., description=\"Human-readable name of the condition.\")\n",
        "    summary: str = Field(..., description=\"A concise narrative summarizing the condition’s status, relevant encounters, medications, and guideline recommendations.\")\n",
        "\n",
        "class CaseSummary(BaseModel):\n",
        "    patient_name: str = Field(..., description=\"The patient's name.\")\n",
        "    age: int = Field(..., description=\"The patient's age in years.\")\n",
        "    overall_assessment: str = Field(..., description=\"A high-level summary synthesizing all conditions, encounters, medications, and guideline recommendations.\")\n",
        "    condition_summaries: List[ConditionSummary] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"A list of condition-specific summaries providing insight into each condition's current management and recommendations.\"\n",
        "    )\n",
        "\n",
        "    def render(self) -> str:\n",
        "        lines = []\n",
        "        lines.append(f\"Patient Name: {self.patient_name}\")\n",
        "        lines.append(f\"Age: {self.age} years\")\n",
        "        lines.append(\"\")\n",
        "        lines.append(\"Overall Assessment:\")\n",
        "        lines.append(self.overall_assessment)\n",
        "        lines.append(\"\")\n",
        "\n",
        "        if self.condition_summaries:\n",
        "            lines.append(\"Condition Summaries:\")\n",
        "            for csum in self.condition_summaries:\n",
        "                lines.append(f\"- {csum.condition_display}:\")\n",
        "                lines.append(f\"  {csum.summary}\")\n",
        "        else:\n",
        "            lines.append(\"No specific conditions were summarized.\")\n",
        "\n",
        "        return \"\\n\".join(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ff8eebc-c00e-4499-ad5d-2d7843786eba",
      "metadata": {
        "id": "0ff8eebc-c00e-4499-ad5d-2d7843786eba"
      },
      "source": [
        "## Setup Patient Case Summary Workflow\n",
        "\n",
        "Let's define the following workflow to generate patient case summaries:\n",
        "1. Extract out patient data including conditions, medications, encounters from the synthetically generated patient JSON (from Synthea)\n",
        "2. Use an LLM to map each condition to relevant medications/encounters (defined as a \"condition bundle\")\n",
        "3. For each condition bundle, generate a set of search queries to match it against relevant medical guidelines in our index.\n",
        "4. Generate final case summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "8b803856-630c-497c-9142-bd5aeb9efa5d",
      "metadata": {
        "id": "8b803856-630c-497c-9142-bd5aeb9efa5d"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.workflow import (\n",
        "    Event,\n",
        "    StartEvent,\n",
        "    StopEvent,\n",
        "    Context,\n",
        "    Workflow,\n",
        "    step,\n",
        ")\n",
        "from llama_index.core.llms import LLM\n",
        "from typing import Optional, Tuple\n",
        "from pydantic import BaseModel\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core.schema import Document\n",
        "from llama_index.core.agent import FunctionCallingAgentWorker\n",
        "from llama_index.core.prompts import ChatPromptTemplate\n",
        "from llama_index.core.llms import ChatMessage, MessageRole\n",
        "from llama_index.core.retrievers import BaseRetriever\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import json\n",
        "import os\n",
        "\n",
        "_logger = logging.getLogger(__name__)\n",
        "_logger.setLevel(logging.INFO)\n",
        "\n",
        "\n",
        "\n",
        "GUIDELINE_QUERIES_PROMPT = \"\"\"\\\n",
        "You are an assistant tasked with determining what guidelines would be most helpful to consult for a given patient's condition data. You have:\n",
        "\n",
        "- Patient information (demographics, conditions, encounters, medications)\n",
        "- A single condition bundle that includes:\n",
        "  - One specific condition and its related encounters and medications\n",
        "- Your goal is to produce several high-quality search queries that can be used to retrieve relevant guideline sections from a vector index of medical guidelines.\n",
        "\n",
        "**Instructions:**\n",
        "1. Review the patient info and the condition bundle. Identify the key aspects of the condition that might require guideline consultation—such as disease severity, typical management steps, trigger avoidance, or medication optimization.\n",
        "2. Consider what clinicians would look up:\n",
        "   - Best practices for this condition's management (e.g., stepwise therapy for asthma, maintenance therapy for atopic dermatitis)\n",
        "   - Medication recommendations (e.g., use of inhaled corticosteroids, timing and dose adjustments, rescue inhaler usage, antihistamines for atopic dermatitis)\n",
        "   - Encounter follow-ups (e.g., what follow-up intervals are recommended, what tests or measurements to track)\n",
        "   - Patient education and preventive measures (e.g., trigger avoidance, skincare routines, inhaler technique)\n",
        "3. Formulate 3-5 concise, targeted queries that, if run against a medical guideline index, would return the most relevant sections. Each query should be a natural language string that could be used with a vector-based retrieval system.\n",
        "4. Make the queries condition-specific, incorporating relevant medications or encounter findings.\n",
        "5. Return the output as a JSON object following the schema defined as a tool call.\n",
        "\n",
        "Patient Info: {patient_info}\n",
        "\n",
        "Condition Bundle: {condition_info}\n",
        "\n",
        "Do not include any commentary outside the JSON.\"\"\"\n",
        "\n",
        "\n",
        "GUIDELINE_RECOMMENDATION_PROMPT = \"\"\"\\\n",
        "Given the following patient condition and the corresponding relevant medical guideline text (unformatted),\n",
        "generate a guideline recommendation according to the schema defined as a tool call.\n",
        "\n",
        "The condition details are given below. This includes the condition itself, along with associated encounters/medications\n",
        "that the patient has taken already. Make sure the guideline recommendation is relevant.\n",
        "\n",
        "**Patient Condition:**\n",
        "{patient_condition_text}\n",
        "\n",
        "**Matched Guideline Text(s):**\n",
        "{guideline_text}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "CASE_SUMMARY_SYSTEM_PROMPT = \"\"\"\\\n",
        "You are a medical assistant that produces a concise and understandable case summary for a clinician.\n",
        "\n",
        "You have access to the patient's name, age, and a list of conditions.\n",
        "\n",
        "For each condition, you also have related encounters, medications, and guideline recommendations.\n",
        "\n",
        "Your goal is to produce a `CaseSummary` object in JSON format that adheres to the CaseSummary schema, defined as a tool call.\n",
        "\n",
        "**Instructions:**\n",
        "- Use the patient's name and age as given.\n",
        "- Create an `overall_assessment` that integrates the data about their conditions, encounters, medications, and guideline recommendations.\n",
        "- For each condition, write a short `summary` describing:\n",
        "  - The current state of the condition.\n",
        "  - Relevant encounters that indicate progress or issues.\n",
        "  - Medications currently managing that condition and if they align with guidelines.\n",
        "  - Any key recommendations from the guidelines that should be followed going forward.\n",
        "- Keep the summaries patient-friendly but medically accurate. Be concise and clear.\n",
        "- Return only the final JSON that matches the schema. No extra commentary.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "CASE_SUMMARY_USER_PROMPT = \"\"\"\\\n",
        "**Patient Demographics**\n",
        "{demographic_info}\n",
        "\n",
        "**Condition Information**\n",
        "{condition_guideline_info}\n",
        "\n",
        "\n",
        "Given the above data, produce a `CaseSummary` as per the schema.\n",
        "\"\"\"\n",
        "\n",
        "def generate_condition_guideline_str(\n",
        "    bundle: ConditionBundle,\n",
        "    rec: GuidelineRecommendation\n",
        ") -> str:\n",
        "    return f\"\"\"\\\n",
        "**Condition Info**:\n",
        "{bundle.json()}\n",
        "\n",
        "**Recommendation**:\n",
        "{rec.json()}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class PatientInfoEvent(Event):\n",
        "    patient_info: PatientInfo\n",
        "\n",
        "\n",
        "class ConditionBundleEvent(Event):\n",
        "    bundles: ConditionBundles\n",
        "\n",
        "\n",
        "class MatchGuidelineEvent(Event):\n",
        "    bundle: ConditionBundle\n",
        "\n",
        "\n",
        "class MatchGuidelineResultEvent(Event):\n",
        "    bundle: ConditionBundle\n",
        "    rec: GuidelineRecommendation\n",
        "\n",
        "\n",
        "class GenerateCaseSummaryEvent(Event):\n",
        "    condition_guideline_info: List[Tuple[ConditionBundle, GuidelineRecommendation]]\n",
        "\n",
        "\n",
        "class LogEvent(Event):\n",
        "    msg: str\n",
        "    delta: bool = False\n",
        "\n",
        "\n",
        "class GuidelineRecommendationWorkflow(Workflow):\n",
        "    \"\"\"Guidline recommendation workflow.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        guideline_retriever: BaseRetriever,\n",
        "        llm: LLM | None = None,\n",
        "        similarity_top_k: int = 20,\n",
        "        output_dir: str = \"data_out\",\n",
        "        **kwargs,\n",
        "    ) -> None:\n",
        "        \"\"\"Init params.\"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.guideline_retriever = guideline_retriever\n",
        "\n",
        "        self.llm = llm or OpenAI(model=\"gpt-4o-mini\")\n",
        "        self.similarity_top_k = similarity_top_k\n",
        "\n",
        "        # if not exists, create\n",
        "        out_path = Path(output_dir) / \"workflow_output\"\n",
        "        if not out_path.exists():\n",
        "            out_path.mkdir(parents=True, exist_ok=True)\n",
        "            os.chmod(str(out_path), 0o0777)\n",
        "        self.output_dir = out_path\n",
        "\n",
        "    @step\n",
        "    async def parse_patient_info(\n",
        "        self, ctx: Context, ev: StartEvent\n",
        "    ) -> PatientInfoEvent:\n",
        "        # load patient info from cache if exists, otherwise generate\n",
        "        patient_info_path = Path(\n",
        "            f\"{self.output_dir}/patient_info.json\"\n",
        "        )\n",
        "        if patient_info_path.exists():\n",
        "            if self._verbose:\n",
        "                ctx.write_event_to_stream(LogEvent(msg=\">> Loading patient info from cache\"))\n",
        "            patient_info_dict = json.load(open(str(patient_info_path), \"r\"))\n",
        "            patient_info = PatientInfo.model_validate(patient_info_dict)\n",
        "        else:\n",
        "            if self._verbose:\n",
        "                ctx.write_event_to_stream(LogEvent(msg=\">> Reading patient info\"))\n",
        "            patient_info = parse_synthea_patient(ev.patient_json_path)\n",
        "\n",
        "            if not isinstance(patient_info, PatientInfo):\n",
        "                raise ValueError(f\"Invalid patient info: {patient_info}\")\n",
        "            # save patient info to file\n",
        "            with open(patient_info_path, \"w\") as fp:\n",
        "                fp.write(patient_info.model_dump_json())\n",
        "        if self._verbose:\n",
        "            ctx.write_event_to_stream(LogEvent(msg=f\">> Patient Info: {patient_info.dict()}\"))\n",
        "\n",
        "        await ctx.set(\"patient_info\", patient_info)\n",
        "\n",
        "        return PatientInfoEvent(patient_info=patient_info)\n",
        "\n",
        "    @step\n",
        "    async def create_condition_bundles(\n",
        "        self, ctx: Context, ev: PatientInfoEvent\n",
        "    ) -> ConditionBundleEvent:\n",
        "        \"\"\"Create condition bundles.\"\"\"\n",
        "        # load patient condition info from cache if exists, otherwise generate\n",
        "        condition_info_path = Path(\n",
        "            f\"{self.output_dir}/condition_bundles.json\"\n",
        "        )\n",
        "        if condition_info_path.exists():\n",
        "            condition_bundles = ConditionBundles.model_validate(\n",
        "                json.load(open(str(condition_info_path), \"r\"))\n",
        "            )\n",
        "        else:\n",
        "            condition_bundles = await create_condition_bundles(ev.patient_info)\n",
        "            with open(condition_info_path, \"w\") as fp:\n",
        "                fp.write(condition_bundles.model_dump_json())\n",
        "\n",
        "        return ConditionBundleEvent(bundles=condition_bundles)\n",
        "\n",
        "    @step\n",
        "    async def dispatch_guideline_match(\n",
        "        self, ctx: Context, ev: ConditionBundleEvent\n",
        "    ) -> MatchGuidelineEvent:\n",
        "        \"\"\"For each condition + associated information, find relevant guidelines.\n",
        "\n",
        "        Use a map-reduce pattern.\n",
        "\n",
        "        \"\"\"\n",
        "        await ctx.set(\"num_conditions\", len(ev.bundles.bundles))\n",
        "\n",
        "        for bundle in ev.bundles.bundles:\n",
        "            ctx.send_event(MatchGuidelineEvent(bundle=bundle))\n",
        "\n",
        "    @step\n",
        "    async def handle_guideline_match(\n",
        "        self, ctx: Context, ev: MatchGuidelineEvent\n",
        "    ) -> MatchGuidelineResultEvent:\n",
        "        \"\"\"Generate guideline recommendation for each condition.\"\"\"\n",
        "        patient_info = await ctx.get(\"patient_info\")\n",
        "\n",
        "        # We will first generate the right set of questions to ask given the patient info.\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"user\", GUIDELINE_QUERIES_PROMPT)\n",
        "        ])\n",
        "        guideline_queries = await llm.astructured_predict(\n",
        "            GuidelineQueries,\n",
        "            prompt,\n",
        "            patient_info=patient_info.demographic_str,\n",
        "            condition_info=ev.bundle.json()\n",
        "        )\n",
        "\n",
        "        guideline_docs_dict = {}\n",
        "        # fetch all relevant guidelines as text\n",
        "        for query in guideline_queries.queries:\n",
        "            if self._verbose:\n",
        "                ctx.write_event_to_stream(LogEvent(msg=f\">> Generating query: {query}\"))\n",
        "            cur_guideline_docs = self.guideline_retriever.retrieve(query)\n",
        "            guideline_docs_dict.update({\n",
        "                d.id_: d for d in cur_guideline_docs\n",
        "            })\n",
        "        guideline_docs = guideline_docs_dict.values()\n",
        "        guideline_text=\"\\n\\n\".join([g.get_content() for g in guideline_docs])\n",
        "        if self._verbose:\n",
        "            ctx.write_event_to_stream(\n",
        "                LogEvent(msg=f\">> Found guidelines: {guideline_text[:200]}...\")\n",
        "            )\n",
        "\n",
        "        # generate guideline recommendation\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"user\", GUIDELINE_RECOMMENDATION_PROMPT)\n",
        "        ])\n",
        "        guideline_rec = await llm.astructured_predict(\n",
        "            GuidelineRecommendation,\n",
        "            prompt,\n",
        "            patient_info=patient_info.demographic_str,\n",
        "            condition_info=ev.bundle.json(),\n",
        "            guideline_text=guideline_text\n",
        "        )\n",
        "        if self._verbose:\n",
        "            ctx.write_event_to_stream(\n",
        "                LogEvent(msg=f\">> Guideline recommendation: {guideline_rec.json()}\")\n",
        "            )\n",
        "\n",
        "        if not isinstance(guideline_rec, GuidelineRecommendation):\n",
        "            raise ValueError(f\"Invalid guideline recommendation: {guideline_rec}\")\n",
        "\n",
        "        return MatchGuidelineResultEvent(bundle=ev.bundle, rec=guideline_rec)\n",
        "\n",
        "    @step\n",
        "    async def gather_guideline_match(\n",
        "        self, ctx: Context, ev: MatchGuidelineResultEvent\n",
        "    ) -> GenerateCaseSummaryEvent:\n",
        "        \"\"\"Handle matching clause against guideline.\"\"\"\n",
        "        num_conditions = await ctx.get(\"num_conditions\")\n",
        "        events = ctx.collect_events(ev, [MatchGuidelineResultEvent] * num_conditions)\n",
        "        if events is None:\n",
        "            return\n",
        "\n",
        "        match_results = [(e.bundle, e.rec) for e in events]\n",
        "        # save match results\n",
        "        recs_path = Path(f\"{self.output_dir}/guideline_recommendations.jsonl\")\n",
        "        with open(recs_path, \"w\") as fp:\n",
        "            for _, rec in match_results:\n",
        "                fp.write(rec.model_dump_json() + \"\\n\")\n",
        "\n",
        "\n",
        "        return GenerateCaseSummaryEvent(condition_guideline_info=match_results)\n",
        "\n",
        "    @step\n",
        "    async def generate_output(\n",
        "        self, ctx: Context, ev: GenerateCaseSummaryEvent\n",
        "    ) -> StopEvent:\n",
        "        if self._verbose:\n",
        "            ctx.write_event_to_stream(LogEvent(msg=\">> Generating Case Summary\"))\n",
        "\n",
        "        patient_info = await ctx.get(\"patient_info\")\n",
        "        demographic_info = patient_info.demographic_str\n",
        "\n",
        "        condition_guideline_strs = []\n",
        "        for condition_bundle, guideline_rec in ev.condition_guideline_info:\n",
        "            condition_guideline_strs.append(\n",
        "                generate_condition_guideline_str(condition_bundle, guideline_rec)\n",
        "            )\n",
        "        condition_guideline_str = \"\\n\\n\".join(condition_guideline_strs)\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", CASE_SUMMARY_SYSTEM_PROMPT),\n",
        "            (\"user\", CASE_SUMMARY_USER_PROMPT)\n",
        "        ])\n",
        "        case_summary = await llm.astructured_predict(\n",
        "            CaseSummary,\n",
        "            prompt,\n",
        "            demographic_info=demographic_info,\n",
        "            condition_guideline_info=condition_guideline_str\n",
        "        )\n",
        "\n",
        "        return StopEvent(result={\"case_summary\": case_summary})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "8557f4a7-ce61-4757-8f35-6785574c57cb",
      "metadata": {
        "id": "8557f4a7-ce61-4757-8f35-6785574c57cb"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-4o-mini\")\n",
        "workflow = GuidelineRecommendationWorkflow(\n",
        "    guideline_retriever=retriever,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    timeout=None,  # don't worry about timeout to make sure it completes\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66d79ab2-1455-4f8f-bde3-8bbd51b7da51",
      "metadata": {
        "id": "66d79ab2-1455-4f8f-bde3-8bbd51b7da51"
      },
      "source": [
        "#### Visualize the workflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-utils-workflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LLEK6DUk1kx",
        "outputId": "b8bf6b86-c684-4c10-8e2d-be6c26b0d7d0"
      },
      "id": "2LLEK6DUk1kx",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-utils-workflow\n",
            "  Downloading llama_index_utils_workflow-0.3.0-py3-none-any.whl.metadata (665 bytes)\n",
            "Collecting llama-index-core<0.13.0,>=0.12.0 (from llama-index-utils-workflow)\n",
            "  Using cached llama_index_core-0.12.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pyvis<0.4.0,>=0.3.2 (from llama-index-utils-workflow)\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.0.8)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2.10.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.17.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (7.34.0)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.10/dist-packages (from pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (3.1.4)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (4.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.18.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9.6->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (3.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (3.23.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (0.14.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.8.4)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (24.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.2.13)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-utils-workflow) (1.2.2)\n",
            "Downloading llama_index_utils_workflow-0.3.0-py3-none-any.whl (2.8 kB)\n",
            "Downloading llama_index_core-0.12.5-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, jedi, pyvis, llama-index-core, llama-index-utils-workflow\n",
            "  Attempting uninstall: llama-index-core\n",
            "    Found existing installation: llama-index-core 0.10.68.post1\n",
            "    Uninstalling llama-index-core-0.10.68.post1:\n",
            "      Successfully uninstalled llama-index-core-0.10.68.post1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llama-index 0.10.68 requires llama-index-core<0.11.0,>=0.10.68, but you have llama-index-core 0.12.5 which is incompatible.\n",
            "llama-index-agent-openai 0.2.9 requires llama-index-core<0.11.0,>=0.10.41, but you have llama-index-core 0.12.5 which is incompatible.\n",
            "llama-index-cli 0.1.13 requires llama-index-core<0.11.0,>=0.10.11.post1, but you have llama-index-core 0.12.5 which is incompatible.\n",
            "llama-index-embeddings-openai 0.1.11 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.5 which is incompatible.\n",
            "llama-index-indices-llama-cloud 0.1.0 requires llama-index-core<0.11.0,>=0.10.0, but you have llama-index-core 0.12.5 which is incompatible.\n",
            "llama-index-indices-managed-llama-cloud 0.2.7 requires llama-index-core<0.11.0,>=0.10.48.post1, but you have llama-index-core 0.12.5 which is incompatible.\n",
            "llama-index-llms-openai 0.1.31 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.12.5 which is incompatible.\n",
            "llama-index-multi-modal-llms-openai 0.1.9 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.5 which is incompatible.\n",
            "llama-index-program-openai 0.1.7 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.12.5 which is incompatible.\n",
            "llama-index-question-gen-openai 0.1.3 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.5 which is incompatible.\n",
            "llama-index-readers-file 0.1.33 requires llama-index-core<0.11.0,>=0.10.37.post1, but you have llama-index-core 0.12.5 which is incompatible.\n",
            "llama-index-readers-llama-parse 0.1.6 requires llama-index-core<0.11.0,>=0.10.7, but you have llama-index-core 0.12.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 jedi-0.19.2 llama-index-core-0.12.5 llama-index-utils-workflow-0.3.0 pyvis-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from llama_index.utils.workflow import draw_all_possible_flows\n",
        "\n",
        "#draw_all_possible_flows(GuidelineRecommendationWorkflow, filename=\"guideline_rec_workflow.html\")"
      ],
      "metadata": {
        "id": "wqm6sUNdlGun"
      },
      "id": "wqm6sUNdlGun",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(Context))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpIaBRs1o7sw",
        "outputId": "0f135421-1bda-42f3-c766-0d7d2917fee1"
      },
      "id": "dpIaBRs1o7sw",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'collect_events', 'data', 'get', 'lock', 'set']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f11484c-52b8-424f-9a64-7456068ff1b1",
      "metadata": {
        "id": "0f11484c-52b8-424f-9a64-7456068ff1b1"
      },
      "source": [
        "## Run the Workflow\n",
        "\n",
        "Let's run the full workflow and generate the output!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b9a55b1b-8263-4365-b187-6204150ec4cb",
      "metadata": {
        "scrolled": true,
        "id": "b9a55b1b-8263-4365-b187-6204150ec4cb",
        "outputId": "fa9842dc-4e4f-411b-f2af-d1b010103619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running step parse_patient_info\n",
            "Step parse_patient_info produced event PatientInfoEvent\n",
            "Running step create_condition_bundles\n",
            "Step create_condition_bundles produced event ConditionBundleEvent\n",
            "Running step dispatch_guideline_match\n",
            "Step dispatch_guideline_match produced no event\n",
            "Running step handle_guideline_match\n",
            "Running step handle_guideline_match\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-4fb3b2345d8e>:191: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  ctx.write_event_to_stream(LogEvent(msg=f\">> Patient Info: {patient_info.dict()}\"))\n",
            "<ipython-input-20-4fb3b2345d8e>:246: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  condition_info=ev.bundle.json()\n",
            "<ipython-input-20-4fb3b2345d8e>:273: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  condition_info=ev.bundle.json(),\n",
            "<ipython-input-20-4fb3b2345d8e>:278: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  LogEvent(msg=f\">> Guideline recommendation: {guideline_rec.json()}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step handle_guideline_match produced event MatchGuidelineResultEvent\n",
            "Running step gather_guideline_match\n",
            "Step gather_guideline_match produced no event\n",
            "Step handle_guideline_match produced event MatchGuidelineResultEvent\n",
            "Running step gather_guideline_match\n",
            "Step gather_guideline_match produced event GenerateCaseSummaryEvent\n",
            "Running step generate_output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-4fb3b2345d8e>:108: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  {bundle.json()}\n",
            "<ipython-input-20-4fb3b2345d8e>:111: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  {rec.json()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step generate_output produced event StopEvent\n",
            "patient_name='Almeta56 Buckridge80' age=12 overall_assessment='Almeta56 Buckridge80 is a 12-year-old female with active childhood asthma and atopic dermatitis. Currently, there are no documented encounters or medications for either condition. It is crucial to initiate management for asthma with low-dose inhaled corticosteroids and for atopic dermatitis with appropriate topical therapies, considering further options if symptoms persist.' condition_summaries=[ConditionSummary(condition_display='Childhood asthma', summary='Almeta56 has active childhood asthma but is currently not on any medications or receiving treatment. According to the 2020 Asthma Management Guidelines, it is recommended to start daily low-dose inhaled corticosteroids and have a short-acting beta2-agonist available for symptom control. Regular assessments of asthma control are essential.'), ConditionSummary(condition_display='Atopic dermatitis', summary='Almeta56 also has active atopic dermatitis with no current treatment. The guidelines suggest starting with topical therapies, and if these are ineffective, considering advanced treatments such as phototherapy or systemic therapies. Regular follow-up is necessary to evaluate the effectiveness of the chosen treatment.')]\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "# Update: Remove the async for loop and handler.stream_events call\n",
        "response_dict = await workflow.run(patient_json_path=\"data/almeta_buckridge.json\")\n",
        "\n",
        "# Print LogEvents directly from response_dict\n",
        "for event in response_dict.get(\"events\", []):  # Assuming events are stored under 'events' key\n",
        "    if isinstance(event, LogEvent):\n",
        "        if event.delta:\n",
        "            print(event.msg, end=\"\")\n",
        "        else:\n",
        "            print(event.msg)\n",
        "\n",
        "print(str(response_dict[\"case_summary\"]))  # Access case summary as before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "bb0f5f52-ced9-49c2-82b9-131470fd291e",
      "metadata": {
        "id": "bb0f5f52-ced9-49c2-82b9-131470fd291e",
        "outputId": "be48dc50-6c44-4a90-e967-bd65726244ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient Name: Almeta56 Buckridge80\n",
            "Age: 12 years\n",
            "\n",
            "Overall Assessment:\n",
            "Almeta56 Buckridge80 is a 12-year-old female with active childhood asthma and atopic dermatitis. Currently, there are no documented encounters or medications for either condition. It is crucial to initiate management for asthma with low-dose inhaled corticosteroids and for atopic dermatitis with appropriate topical therapies, considering further options if symptoms persist.\n",
            "\n",
            "Condition Summaries:\n",
            "- Childhood asthma:\n",
            "  Almeta56 has active childhood asthma but is currently not on any medications or receiving treatment. According to the 2020 Asthma Management Guidelines, it is recommended to start daily low-dose inhaled corticosteroids and have a short-acting beta2-agonist available for symptom control. Regular assessments of asthma control are essential.\n",
            "- Atopic dermatitis:\n",
            "  Almeta56 also has active atopic dermatitis with no current treatment. The guidelines suggest starting with topical therapies, and if these are ineffective, considering advanced treatments such as phototherapy or systemic therapies. Regular follow-up is necessary to evaluate the effectiveness of the chosen treatment.\n"
          ]
        }
      ],
      "source": [
        "print(str(response_dict[\"case_summary\"].render()))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llamacloud-demo",
      "language": "python",
      "name": "llamacloud-demo"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}