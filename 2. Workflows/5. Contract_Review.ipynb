{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a65d3850-3ddb-4db3-87fe-fa7d92e6c55b",
      "metadata": {
        "id": "a65d3850-3ddb-4db3-87fe-fa7d92e6c55b"
      },
      "source": [
        "# Contract Review Workflow\n",
        "\n",
        "*   Updated by: Wilfredo Aaron Sosa Ramos\n",
        "*   Credits to: https://github.com/run-llama/llamacloud-demo/blob/main/examples/document_workflows/contract_review/contract_review.ipynb\n",
        "\n",
        "![](contract_review.png)\n",
        "\n",
        "This tutorial shows you how to create an agentic workflow that can review a contract for compliance with certain regulations. We will parse the contract into a set of key clauses, match it with relevant clauses from a guideline repository (here, we specifically do GDPR), and then produce a compliance summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "87c5f0d7-c884-475a-88ff-4b7057bb91a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87c5f0d7-c884-475a-88ff-4b7057bb91a6",
        "outputId": "a83a75ec-0f62-4fee-984e-18201a9db51a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.3/454.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q llama-index llama-index-indices-managed-llama-cloud llama-cloud llama-parse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q llama-index-utils-workflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkmosZK-5hjP",
        "outputId": "2f2487a9-95e2-4b7c-8e4a-8a4702a6a22f"
      },
      "id": "TkmosZK-5hjP",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/756.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8fe98ed0-cfcb-4c37-ac5a-7140d79fefd0",
      "metadata": {
        "id": "8fe98ed0-cfcb-4c37-ac5a-7140d79fefd0"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d76541e7-65d3-4c70-afcd-49658bc00954",
      "metadata": {
        "id": "d76541e7-65d3-4c70-afcd-49658bc00954"
      },
      "source": [
        "## Setup\n",
        "\n",
        "We setup an index for guidelines. In this case it's just the GDPR document.\n",
        "\n",
        "We also setup our parser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dec74e08-72fc-4ed8-9e13-e1ed609ed890",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dec74e08-72fc-4ed8-9e13-e1ed609ed890",
        "outputId": "4d8f850e-10aa-4e00-e4da-45d7d6515791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-25 17:40:16--  https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32016R0679\n",
            "Resolving eur-lex.europa.eu (eur-lex.europa.eu)... 52.85.132.127, 52.85.132.11, 52.85.132.12, ...\n",
            "Connecting to eur-lex.europa.eu (eur-lex.europa.eu)|52.85.132.127|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/pdf]\n",
            "Saving to: ‘data/gdpr.pdf’\n",
            "\n",
            "data/gdpr.pdf           [ <=>                ] 959.27K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-12-25 17:40:16 (69.7 MB/s) - ‘data/gdpr.pdf’ saved [982296]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p data\n",
        "!wget \"https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32016R0679\" -O data/gdpr.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e01c7a8f-25f9-4f3b-b040-ee15d34826f6",
      "metadata": {
        "id": "e01c7a8f-25f9-4f3b-b040-ee15d34826f6"
      },
      "source": [
        "### Setup Index\n",
        "Here we use LlamaCloud: https://cloud.llamaindex.ai/. If you don't have access yet, you're always welcome to use our open-source VectorStoreIndex."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade llama-index-core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgxroUj96JGX",
        "outputId": "23e9d8f8-d5e1-4c28-cf9f-db97c9bb0df3"
      },
      "id": "KgxroUj96JGX",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index-core in /usr/local/lib/python3.10/dist-packages (0.12.8)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (2.10.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.18.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8.0->llama-index-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8.0->llama-index-core) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core) (3.23.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core) (0.14.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core) (24.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "LnRISbqH6UpH"
      },
      "id": "LnRISbqH6UpH",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option 2 - LlamaCloud:"
      ],
      "metadata": {
        "id": "0N7994KX6luf"
      },
      "id": "0N7994KX6luf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07ccec03-9aaf-42c7-99e1-f7187328548b",
      "metadata": {
        "id": "07ccec03-9aaf-42c7-99e1-f7187328548b"
      },
      "outputs": [],
      "source": [
        "# option 1\n",
        "from llama_index.indices.managed.llama_cloud import LlamaCloudIndex\n",
        "\n",
        "index = LlamaCloudIndex(\n",
        "  name=\"gdpr\",\n",
        "  project_name=\"llamacloud_demo\",\n",
        "  organization_id=\"cdcb3478-1348-492e-8aa0-25f47d1a3902\",\n",
        "  # api_key=\"llx-...\"\n",
        ")\n",
        "\n",
        "retriever = index.as_retriever(similarity_top_k=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option 2 - Open Source Index:"
      ],
      "metadata": {
        "id": "6VLVuv9O6gES"
      },
      "id": "6VLVuv9O6gES"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "# Load documents and build index\n",
        "documents = SimpleDirectoryReader(\n",
        "    \"/content/data\"\n",
        ").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "id": "nq0CrNfH6PtW"
      },
      "id": "nq0CrNfH6PtW",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = index.as_retriever(similarity_top_k=3)"
      ],
      "metadata": {
        "id": "zZTaUbaH6e-7"
      },
      "id": "zZTaUbaH6e-7",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1e5d1dfc-5d1e-4acd-80c9-616bd9aff3cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e5d1dfc-5d1e-4acd-80c9-616bd9aff3cb",
        "outputId": "c89b1cdc-0657-4d9e-dbf3-37d155ea5d70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bb66d70-58e2-46cf-8dc7-9188a70891f3",
      "metadata": {
        "id": "2bb66d70-58e2-46cf-8dc7-9188a70891f3"
      },
      "source": [
        "### Setup Parser\n",
        "\n",
        "Here we use LlamaParse to parse the vendor agremeent."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llama_parse_api_key = userdata.get('LLAMA_CLOUD_API_KEY')"
      ],
      "metadata": {
        "id": "G4aP3Swe7F1C"
      },
      "id": "G4aP3Swe7F1C",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8af32038-7ce0-49f0-9d67-bf7260a3f27f",
      "metadata": {
        "id": "8af32038-7ce0-49f0-9d67-bf7260a3f27f"
      },
      "outputs": [],
      "source": [
        "from llama_parse import LlamaParse\n",
        "\n",
        "# use our multimodal models for extractions\n",
        "parser = LlamaParse(result_type=\"markdown\", api_key=llama_parse_api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e634cc0d-fc3f-4864-ae64-7d681647cc10",
      "metadata": {
        "id": "e634cc0d-fc3f-4864-ae64-7d681647cc10"
      },
      "source": [
        "### Define Contract Output Schema\n",
        "\n",
        "We want to extract relevant clauses from the agreement in order to match it against relevant clauses in the GDPR. This schema defines a way to structuring the set of extracted clauses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8d3aceab-26cb-424d-9b24-624e11550901",
      "metadata": {
        "id": "8d3aceab-26cb-424d-9b24-624e11550901"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class ContractClause(BaseModel):\n",
        "    clause_text: str = Field(..., description=\"The exact text of the clause.\")\n",
        "    mentions_data_processing: bool = Field(False, description=\"True if the clause involves personal data collection or usage.\")\n",
        "    mentions_data_transfer: bool = Field(False, description=\"True if the clause involves transferring personal data, especially to third parties or across borders.\")\n",
        "    requires_consent: bool = Field(False, description=\"True if the clause explicitly states that user consent is needed for data activities.\")\n",
        "    specifies_purpose: bool = Field(False, description=\"True if the clause specifies a clear purpose for data handling or transfer.\")\n",
        "    mentions_safeguards: bool = Field(False, description=\"True if the clause mentions security measures or other safeguards for data.\")\n",
        "\n",
        "class ContractExtraction(BaseModel):\n",
        "    vendor_name: Optional[str] = Field(None, description=\"The vendor's name if identifiable.\")\n",
        "    effective_date: Optional[str] = Field(None, description=\"The effective date of the agreement, if available.\")\n",
        "    governing_law: Optional[str] = Field(None, description=\"The governing law of the contract, if stated.\")\n",
        "    clauses: List[ContractClause] = Field(..., description=\"List of extracted clauses and their relevant indicators.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a4a1d37-c8c8-48ab-b394-51bb2412f3b5",
      "metadata": {
        "id": "9a4a1d37-c8c8-48ab-b394-51bb2412f3b5"
      },
      "source": [
        "### Define Compliance Check Schema\n",
        "\n",
        "Define a schema that matches clauses with relevant guidelines in GDPR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7d0e0f4f-5f82-46b0-92a2-3e47fc061de3",
      "metadata": {
        "id": "7d0e0f4f-5f82-46b0-92a2-3e47fc061de3"
      },
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class GuidelineMatch(BaseModel):\n",
        "    guideline_text: str = Field(..., description=\"The single most relevant guideline excerpt related to this clause.\")\n",
        "    similarity_score: float = Field(..., description=\"Similarity score indicating how closely the guideline matches the clause, e.g., between 0 and 1.\")\n",
        "    relevance_explanation: Optional[str] = Field(None, description=\"Brief explanation of why this guideline is relevant.\")\n",
        "\n",
        "class ClauseComplianceCheck(BaseModel):\n",
        "    clause_text: str = Field(..., description=\"The exact text of the clause from the contract.\")\n",
        "    matched_guideline: Optional[GuidelineMatch] = Field(None, description=\"The most relevant guideline extracted via vector retrieval.\")\n",
        "    compliant: bool = Field(..., description=\"Indicates whether the clause is considered compliant with the referenced guideline.\")\n",
        "    notes: Optional[str] = Field(None, description=\"Additional commentary or recommendations.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15e1805c-a9ad-433c-8f22-a005de3fe0ab",
      "metadata": {
        "id": "15e1805c-a9ad-433c-8f22-a005de3fe0ab"
      },
      "source": [
        "### Define Final Output Schema\n",
        "\n",
        "This is the schema for the final compliance report. It contains the vendor name, if it's overall compliant, and also the summary notes.\n",
        "\n",
        "It will be inferred from the individual checks for every clause."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b9f275f4-66cc-4950-93f7-47da98d14e96",
      "metadata": {
        "id": "b9f275f4-66cc-4950-93f7-47da98d14e96"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, List\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class ComplianceReport(BaseModel):\n",
        "    vendor_name: Optional[str] = Field(None, description=\"The vendor's name if identified from the contract.\")\n",
        "    overall_compliant: bool = Field(..., description=\"Indicates if the contract is considered overall compliant.\")\n",
        "    summary_notes: Optional[str] = Field(None, description=\"General summary or recommendations for achieving full compliance.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ff8eebc-c00e-4499-ad5d-2d7843786eba",
      "metadata": {
        "id": "0ff8eebc-c00e-4499-ad5d-2d7843786eba"
      },
      "source": [
        "## Setup Contract Review Workflow\n",
        "\n",
        "Let's define the following contract review workflow:\n",
        "1. Extract out structured data from the vendor agreement.\n",
        "2. For each clause, do retrieval against GDPR to see if it's compliant with guidelines.\n",
        "3. Generate a final summary."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.workflow import (\n",
        "    Context,\n",
        ")\n",
        "\n",
        "print(dir(Context))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4Uost_f7gL3",
        "outputId": "0b6df393-a14a-4735-8f68-cf6d00ae4fad"
      },
      "id": "R4Uost_f7gL3",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_deserialize_globals', '_deserialize_queue', '_serialize_globals', '_serialize_queue', 'collect_events', 'data', 'from_dict', 'get', 'get_result', 'lock', 'mark_in_progress', 'remove_from_in_progress', 'send_event', 'session', 'set', 'streaming_queue', 'to_dict', 'write_event_to_stream']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "8b803856-630c-497c-9142-bd5aeb9efa5d",
      "metadata": {
        "id": "8b803856-630c-497c-9142-bd5aeb9efa5d"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.workflow import (\n",
        "    Event,\n",
        "    StartEvent,\n",
        "    StopEvent,\n",
        "    Context,\n",
        "    Workflow,\n",
        "    step,\n",
        ")\n",
        "from llama_index.core.llms import LLM\n",
        "from typing import Optional\n",
        "from pydantic import BaseModel\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core.schema import Document\n",
        "from llama_index.core.agent import FunctionCallingAgentWorker\n",
        "from llama_index.core.prompts import ChatPromptTemplate\n",
        "from llama_index.core.llms import ChatMessage, MessageRole\n",
        "from llama_index.core.retrievers import BaseRetriever\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import json\n",
        "import os\n",
        "\n",
        "_logger = logging.getLogger(__name__)\n",
        "_logger.setLevel(logging.INFO)\n",
        "\n",
        "\n",
        "CONTRACT_EXTRACT_PROMPT = \"\"\"\\\n",
        "You are given contract data below. \\\n",
        "Please extract out relevant information from the contract into the defined schema - the schema is defined as a function call.\\\n",
        "\n",
        "{contract_data}\n",
        "\"\"\"\n",
        "\n",
        "CONTRACT_MATCH_PROMPT = \"\"\"\\\n",
        "Given the following contract clause and the corresponding relevant guideline text, evaluate the compliance \\\n",
        "and provide a JSON object that matches the ClauseComplianceCheck schema.\n",
        "\n",
        "**Contract Clause:**\n",
        "{clause_text}\n",
        "\n",
        "**Matched Guideline Text(s):**\n",
        "{guideline_text}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "COMPLIANCE_REPORT_SYSTEM_PROMPT = \"\"\"\\\n",
        "You are a compliance reporting assistant. Your task is to generate a final compliance report \\\n",
        "based on the results of clause compliance checks against \\\n",
        "a given set of guidelines.\n",
        "\n",
        "Analyze the provided compliance results and produce a structured report according to the specified schema.\n",
        "Ensure that if there are no noncompliant clauses, the report clearly indicates full compliance.\n",
        "\"\"\"\n",
        "\n",
        "COMPLIANCE_REPORT_USER_PROMPT = \"\"\"\\\n",
        "A set of clauses within a contract were checked against GDPR compliance guidelines for the following vendor: {vendor_name}.\n",
        "The set of noncompliant clauses are given below.\n",
        "\n",
        "Each section includes:\n",
        "- **Clause:** The exact text of the contract clause.\n",
        "- **Guideline:** The relevant GDPR guideline text.\n",
        "- **Compliance Status:** Should be `False` for noncompliant clauses.\n",
        "- **Notes:** Additional information or explanations.\n",
        "\n",
        "{compliance_results}\n",
        "\n",
        "Based on the above compliance results, generate a final compliance report following the `ComplianceReport` schema below.\n",
        "If there are no noncompliant clauses, the report should indicate that the contract is fully compliant.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class ContractExtractionEvent(Event):\n",
        "    contract_extraction: ContractExtraction\n",
        "\n",
        "\n",
        "class MatchGuidelineEvent(Event):\n",
        "    clause: ContractClause\n",
        "\n",
        "\n",
        "class MatchGuidelineResultEvent(Event):\n",
        "    result: ClauseComplianceCheck\n",
        "\n",
        "\n",
        "class GenerateReportEvent(Event):\n",
        "    match_results: List[ClauseComplianceCheck]\n",
        "\n",
        "\n",
        "class LogEvent(Event):\n",
        "    msg: str\n",
        "    delta: bool = False\n",
        "\n",
        "\n",
        "class ContractReviewWorkflow(Workflow):\n",
        "    \"\"\"Contract review workflow.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        parser: LlamaParse,\n",
        "        guideline_retriever: BaseRetriever,\n",
        "        llm: LLM | None = None,\n",
        "        similarity_top_k: int = 20,\n",
        "        output_dir: str = \"data_out\",\n",
        "        **kwargs,\n",
        "    ) -> None:\n",
        "        \"\"\"Init params.\"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.parser = parser\n",
        "        self.guideline_retriever = guideline_retriever\n",
        "\n",
        "        self.llm = llm or OpenAI(model=\"gpt-4o-mini\")\n",
        "        self.similarity_top_k = similarity_top_k\n",
        "\n",
        "        # if not exists, create\n",
        "        out_path = Path(output_dir) / \"workflow_output\"\n",
        "        if not out_path.exists():\n",
        "            out_path.mkdir(parents=True, exist_ok=True)\n",
        "            os.chmod(str(out_path), 0o0777)\n",
        "        self.output_dir = out_path\n",
        "\n",
        "    @step\n",
        "    async def parse_contract(\n",
        "        self, ctx: Context, ev: StartEvent\n",
        "    ) -> ContractExtractionEvent:\n",
        "        # load output template file\n",
        "        contract_extraction_path = Path(\n",
        "            f\"{self.output_dir}/contract_extraction.json\"\n",
        "        )\n",
        "        if contract_extraction_path.exists():\n",
        "            if self._verbose:\n",
        "                ctx.write_event_to_stream(LogEvent(msg=\">> Loading contract from cache\"))\n",
        "            contract_extraction_dict = json.load(open(str(contract_extraction_path), \"r\"))\n",
        "            contract_extraction = ContractExtraction.model_validate(contract_extraction_dict)\n",
        "        else:\n",
        "            if self._verbose:\n",
        "                ctx.write_event_to_stream(LogEvent(msg=\">> Reading contract\"))\n",
        "\n",
        "            # no need to parse contract, it's already in markdown\n",
        "            # you can use LlamaParse to parse more complex PDFs + other docs\n",
        "\n",
        "            docs = SimpleDirectoryReader(input_files=[ev.contract_path]).load_data()\n",
        "\n",
        "            # extract from contract\n",
        "            prompt = ChatPromptTemplate.from_messages([\n",
        "                (\"user\", CONTRACT_EXTRACT_PROMPT)\n",
        "            ])\n",
        "            contract_extraction = await llm.astructured_predict(\n",
        "                ContractExtraction,\n",
        "                prompt,\n",
        "                contract_data=\"\\n\".join([d.get_content(metadata_mode=\"all\") for d in docs])\n",
        "            )\n",
        "            if not isinstance(contract_extraction, ContractExtraction):\n",
        "                raise ValueError(f\"Invalid extraction from contract: {contract_extraction}\")\n",
        "            # save output template to file\n",
        "            with open(contract_extraction_path, \"w\") as fp:\n",
        "                fp.write(contract_extraction.model_dump_json())\n",
        "        if self._verbose:\n",
        "            ctx.write_event_to_stream(LogEvent(msg=f\">> Contract data: {contract_extraction.dict()}\"))\n",
        "\n",
        "        return ContractExtractionEvent(contract_extraction=contract_extraction)\n",
        "\n",
        "    @step\n",
        "    async def dispatch_guideline_match(\n",
        "        self, ctx: Context, ev: ContractExtractionEvent\n",
        "    ) -> MatchGuidelineEvent:\n",
        "        \"\"\"For each clause in the contract, find relevant guidelines.\n",
        "\n",
        "        Use a map-reduce pattern.\n",
        "\n",
        "        \"\"\"\n",
        "        await ctx.set(\"num_clauses\", len(ev.contract_extraction.clauses))\n",
        "        await ctx.set(\"vendor_name\", ev.contract_extraction.vendor_name)\n",
        "\n",
        "        for clause in ev.contract_extraction.clauses:\n",
        "            ctx.send_event(MatchGuidelineEvent(clause=clause, vendor_name=ev.contract_extraction.vendor_name))\n",
        "\n",
        "    @step\n",
        "    async def handle_guideline_match(\n",
        "        self, ctx: Context, ev: MatchGuidelineEvent\n",
        "    ) -> MatchGuidelineResultEvent:\n",
        "        \"\"\"Handle matching clause against guideline.\"\"\"\n",
        "\n",
        "        # retrieve matching guideline\n",
        "        query = f\"\"\"\\\n",
        "Please find the relevant guideline from {ev.vendor_name} that aligns with the following contract clause:\n",
        "\n",
        "{ev.clause.clause_text}\n",
        "\"\"\"\n",
        "        guideline_docs = self.guideline_retriever.retrieve(query)\n",
        "        guideline_text=\"\\n\\n\".join([g.get_content() for g in guideline_docs])\n",
        "        if self._verbose:\n",
        "            ctx.write_event_to_stream(\n",
        "                LogEvent(msg=f\">> Found guidelines: {guideline_text[:200]}...\")\n",
        "            )\n",
        "\n",
        "        # extract from contract\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"user\", CONTRACT_MATCH_PROMPT)\n",
        "        ])\n",
        "        compliance_output = await llm.astructured_predict(\n",
        "            ClauseComplianceCheck,\n",
        "            prompt,\n",
        "            clause_text=ev.clause.model_dump_json(),\n",
        "            guideline_text=guideline_text\n",
        "\n",
        "        )\n",
        "\n",
        "        if not isinstance(compliance_output, ClauseComplianceCheck):\n",
        "            raise ValueError(f\"Invalid compliance check: {compliance_output}\")\n",
        "\n",
        "        return MatchGuidelineResultEvent(result=compliance_output)\n",
        "\n",
        "    @step\n",
        "    async def gather_guideline_match(\n",
        "        self, ctx: Context, ev: MatchGuidelineResultEvent\n",
        "    ) -> GenerateReportEvent:\n",
        "        \"\"\"Handle matching clause against guideline.\"\"\"\n",
        "        num_clauses = await ctx.get(\"num_clauses\")\n",
        "        events = ctx.collect_events(ev, [MatchGuidelineResultEvent] * num_clauses)\n",
        "        if events is None:\n",
        "            return\n",
        "\n",
        "        match_results = [e.result for e in events]\n",
        "        # save match results\n",
        "        match_results_path = Path(\n",
        "            f\"{self.output_dir}/match_results.jsonl\"\n",
        "        )\n",
        "        with open(match_results_path, \"w\") as fp:\n",
        "            for mr in match_results:\n",
        "                fp.write(mr.model_dump_json() + \"\\n\")\n",
        "\n",
        "\n",
        "        return GenerateReportEvent(match_results=[e.result for e in events])\n",
        "\n",
        "    @step\n",
        "    async def generate_output(\n",
        "        self, ctx: Context, ev: GenerateReportEvent\n",
        "    ) -> StopEvent:\n",
        "        if self._verbose:\n",
        "            ctx.write_event_to_stream(LogEvent(msg=\">> Generating Compliance Report\"))\n",
        "\n",
        "        # if all clauses are compliant, return a compliant result\n",
        "        non_compliant_results = [r for r in ev.match_results if not r.compliant]\n",
        "\n",
        "        # generate compliance results string\n",
        "        result_tmpl = \"\"\"\n",
        "1. **Clause**: {clause}\n",
        "2. **Guideline:** {guideline}\n",
        "3. **Compliance Status:** {compliance_status}\n",
        "4. **Notes:** {notes}\n",
        "\"\"\"\n",
        "        non_compliant_strings = []\n",
        "        for nr in non_compliant_results:\n",
        "            non_compliant_strings.append(\n",
        "                result_tmpl.format(\n",
        "                    clause=nr.clause_text,\n",
        "                    guideline=nr.matched_guideline.guideline_text,\n",
        "                    compliance_status=nr.compliant,\n",
        "                    notes=nr.notes\n",
        "                )\n",
        "            )\n",
        "        non_compliant_str = \"\\n\\n\".join(non_compliant_strings)\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", COMPLIANCE_REPORT_SYSTEM_PROMPT),\n",
        "            (\"user\", COMPLIANCE_REPORT_USER_PROMPT)\n",
        "        ])\n",
        "        compliance_report = await llm.astructured_predict(\n",
        "            ComplianceReport,\n",
        "            prompt,\n",
        "            compliance_results=non_compliant_str,\n",
        "            vendor_name=await ctx.get(\"vendor_name\")\n",
        "        )\n",
        "\n",
        "        return StopEvent(result={\"report\": compliance_report, \"non_compliant_results\": non_compliant_results})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8557f4a7-ce61-4757-8f35-6785574c57cb",
      "metadata": {
        "id": "8557f4a7-ce61-4757-8f35-6785574c57cb"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-4o\")\n",
        "workflow = ContractReviewWorkflow(\n",
        "    parser=parser,\n",
        "    guideline_retriever=retriever,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    timeout=None,  # don't worry about timeout to make sure it completes\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66d79ab2-1455-4f8f-bde3-8bbd51b7da51",
      "metadata": {
        "id": "66d79ab2-1455-4f8f-bde3-8bbd51b7da51"
      },
      "source": [
        "#### Visualize the workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "470f298b-c3a3-485e-a440-b0576e45134d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "470f298b-c3a3-485e-a440-b0576e45134d",
        "outputId": "634f2cda-2066-4087-88d9-9c8465dfbc6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'NoneType'>\n",
            "<class '__main__.MatchGuidelineEvent'>\n",
            "<class '__main__.GenerateReportEvent'>\n",
            "<class 'llama_index.core.workflow.events.StopEvent'>\n",
            "<class '__main__.MatchGuidelineResultEvent'>\n",
            "<class '__main__.ContractExtractionEvent'>\n",
            "contract_workflow.html\n"
          ]
        }
      ],
      "source": [
        "from llama_index.utils.workflow import draw_all_possible_flows\n",
        "\n",
        "draw_all_possible_flows(ContractReviewWorkflow, filename=\"contract_workflow.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f11484c-52b8-424f-9a64-7456068ff1b1",
      "metadata": {
        "id": "0f11484c-52b8-424f-9a64-7456068ff1b1"
      },
      "source": [
        "## Run the Workflow\n",
        "\n",
        "Let's run the full workflow and generate the output!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b9a55b1b-8263-4365-b187-6204150ec4cb",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9a55b1b-8263-4365-b187-6204150ec4cb",
        "outputId": "77c76339-fb9c-43af-d167-8fb0844986cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running step parse_contract\n",
            ">> Reading contract\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-4f5a784640a7>:158: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  ctx.write_event_to_stream(LogEvent(msg=f\">> Contract data: {contract_extraction.dict()}\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step parse_contract produced event ContractExtractionEvent\n",
            ">> Contract data: {'vendor_name': 'ACME Office Supply, Inc.', 'effective_date': 'January 1, 2024', 'governing_law': 'Ireland', 'clauses': [{'clause_text': 'Vendor shall process Personal Data only: - To fulfill orders and manage deliveries - To provide customer support services - To maintain business records - To comply with legal obligations', 'mentions_data_processing': True, 'mentions_data_transfer': False, 'requires_consent': False, 'specifies_purpose': True, 'mentions_safeguards': False}, {'clause_text': 'Vendor shall: - Respond to data subject requests within 30 days - Provide data in a structured, commonly used format - Implement measures to facilitate data portability - Assist with data subject rights requests at no additional cost', 'mentions_data_processing': True, 'mentions_data_transfer': False, 'requires_consent': False, 'specifies_purpose': False, 'mentions_safeguards': False}, {'clause_text': '- Vendor maintains primary data centers in the United States - Vendor may transfer data to any country where it maintains operations - No prior notification required for new data storage locations - Vendor will rely on its standard data transfer mechanisms - Data may be processed by staff operating outside the EEA', 'mentions_data_processing': False, 'mentions_data_transfer': True, 'requires_consent': False, 'specifies_purpose': False, 'mentions_safeguards': False}, {'clause_text': '- Vendor may engage subprocessors without prior Client approval - Subprocessors may be located in any jurisdiction globally - Notice of new subprocessors provided within 30 days of engagement - Client has no right to object to new subprocessors', 'mentions_data_processing': False, 'mentions_data_transfer': True, 'requires_consent': False, 'specifies_purpose': False, 'mentions_safeguards': False}, {'clause_text': 'Vendor shall implement appropriate measures including: - Encryption of Personal Data in transit and at rest - Access controls and authentication - Regular security testing and assessments - Employee training on data protection - Incident response procedures', 'mentions_data_processing': False, 'mentions_data_transfer': False, 'requires_consent': False, 'specifies_purpose': False, 'mentions_safeguards': True}, {'clause_text': \"Vendor shall: - Notify Client of any Personal Data breach within 72 hours - Provide details necessary to meet regulatory requirements - Cooperate with Client's breach investigation - Maintain records of all data breaches\", 'mentions_data_processing': False, 'mentions_data_transfer': False, 'requires_consent': False, 'specifies_purpose': False, 'mentions_safeguards': True}, {'clause_text': '- Personal Data retained only as long as necessary - Standard retention period of 3 years after last transaction - Deletion of Personal Data upon written request - Backup copies retained for maximum of 6 months', 'mentions_data_processing': True, 'mentions_data_transfer': False, 'requires_consent': False, 'specifies_purpose': False, 'mentions_safeguards': False}, {'clause_text': 'Upon termination of services: - Return all Personal Data in standard format - Delete existing copies within 30 days - Provide written confirmation of deletion - Cease all processing activities', 'mentions_data_processing': True, 'mentions_data_transfer': False, 'requires_consent': False, 'specifies_purpose': False, 'mentions_safeguards': False}, {'clause_text': 'Vendor shall maintain: - Records of all processing activities - Security measure documentation - Data transfer mechanisms - Subprocessor agreements', 'mentions_data_processing': True, 'mentions_data_transfer': False, 'requires_consent': False, 'specifies_purpose': False, 'mentions_safeguards': False}, {'clause_text': '- Annual compliance audits permitted - 30 days notice required for audits - Vendor to provide necessary documentation - Client bears reasonable audit costs', 'mentions_data_processing': True, 'mentions_data_transfer': False, 'requires_consent': False, 'specifies_purpose': False, 'mentions_safeguards': False}, {'clause_text': '- Vendor liable for data protection violations - Reasonable compensation for damages - Coverage for regulatory fines where applicable - Joint liability as required by law', 'mentions_data_processing': True, 'mentions_data_transfer': False, 'requires_consent': False, 'specifies_purpose': False, 'mentions_safeguards': False}]}\n",
            "Running step dispatch_guideline_match\n",
            "Step dispatch_guideline_match produced no event\n",
            "Running step handle_guideline_match\n",
            "Running step handle_guideline_match\n",
            "Running step handle_guideline_match\n",
            "Running step handle_guideline_match\n",
            ">> Found guidelines: It should be possible to entr ust super vision of such data processing operations to specific bodies within \n",
            "the judicial system of the Member State , which should, in par ticular ensure compl iance w...\n",
            ">> Found guidelines: Given that c hildren mer it specifi c protection, any inf or mation and communication, \n",
            "where processing is addressed to a child, should be in such a clear and plain language that the c hild can easil...\n",
            ">> Found guidelines: standard data-protecti on clauses in a wider contract, such as a contract between the processor and another \n",
            "processor , nor from adding other clauses or additional safe guards pro vided that they do ...\n",
            ">> Found guidelines: 2. Where the controller or processor has establishments in several Member Stat es or where a signif icant number of \n",
            "data subjects in more than one Member State are likely to be substantially affe cte...\n",
            "Step handle_guideline_match produced event MatchGuidelineResultEvent\n",
            "Running step handle_guideline_match\n",
            "Running step gather_guideline_match\n",
            "Step gather_guideline_match produced no event\n",
            ">> Found guidelines: (b)  the ability to ensure the ongoing confidentiality , int egr ity , availabi lity and resilience of processing syste ms and \n",
            "ser vices; \n",
            "(c)  the ability to restore the av ailability and access to ...\n",
            "Step handle_guideline_match produced event MatchGuidelineResultEvent\n",
            "Running step handle_guideline_match\n",
            "Running step gather_guideline_match\n",
            "Step gather_guideline_match produced no event\n",
            ">> Found guidelines: awar e that a personal data breach has occur red, the controller should notify the personal data breac h to the \n",
            "super visor y author ity without undue dela y and, where feasible, not later than 72 ho...\n",
            "Step handle_guideline_match produced event MatchGuidelineResultEvent\n",
            "Running step handle_guideline_match\n",
            "Running step gather_guideline_match\n",
            "Step gather_guideline_match produced no event\n",
            ">> Found guidelines: (b)  the ability to ensure the ongoing confidentiality , int egr ity , availabi lity and resilience of processing syste ms and \n",
            "ser vices; \n",
            "(c)  the ability to restore the av ailability and access to ...\n",
            "Step handle_guideline_match produced event MatchGuidelineResultEvent\n",
            "Running step handle_guideline_match\n",
            "Running step gather_guideline_match\n",
            "Step gather_guideline_match produced no event\n",
            ">> Found guidelines: Given that c hildren mer it specifi c protection, any inf or mation and communication, \n",
            "where processing is addressed to a child, should be in such a clear and plain language that the c hild can easil...\n",
            "Step handle_guideline_match produced event MatchGuidelineResultEvent\n",
            "Running step handle_guideline_match\n",
            "Running step gather_guideline_match\n",
            "Step gather_guideline_match produced no event\n",
            ">> Found guidelines: With regar d to point (h) of the fi rst subparagraph, the processor shall immediately inf or m the controller if, in its \n",
            "opinion, an instr uction infr inges this Regulation or other U nion or Member ...\n",
            "Step handle_guideline_match produced event MatchGuidelineResultEvent\n",
            "Running step handle_guideline_match\n",
            "Running step gather_guideline_match\n",
            "Step gather_guideline_match produced no event\n",
            ">> Found guidelines: 10. The Commission shall ensure appropr iat e publicity f or the appro ved codes whic h hav e been decided as having \n",
            "ge neral validity in accordance with paragraph 9. \n",
            "11. The Board shall collat e al...\n",
            "Step handle_guideline_match produced event MatchGuidelineResultEvent\n",
            "Running step handle_guideline_match\n",
            "Running step gather_guideline_match\n",
            "Step gather_guideline_match produced no event\n",
            ">> Found guidelines: Ar ticle 80 \n",
            "Represent ation of dat a subjects \n",
            "1. The data subject shall hav e the r ight to mandate a not-f or -profit body , org anisation or association whic h has been \n",
            "properly constituted in ac...\n",
            "Step handle_guideline_match produced event MatchGuidelineResultEvent\n",
            "Step handle_guideline_match produced event MatchGuidelineResultEvent\n",
            "Running step gather_guideline_match\n",
            "Step gather_guideline_match produced no event\n",
            "Running step gather_guideline_match\n",
            "Step gather_guideline_match produced no event\n",
            "Step handle_guideline_match produced event MatchGuidelineResultEvent\n",
            "Running step gather_guideline_match\n",
            "Step gather_guideline_match produced no event\n",
            "Step handle_guideline_match produced event MatchGuidelineResultEvent\n",
            "Running step gather_guideline_match\n",
            "Step gather_guideline_match produced event GenerateReportEvent\n",
            "Running step generate_output\n",
            ">> Generating Compliance Report\n",
            "Step generate_output produced event StopEvent\n",
            "vendor_name='ACME Office Supply, Inc.' overall_compliant=False summary_notes='The contract contains noncompliant clauses regarding subprocessors and data transfer mechanisms. It lacks provisions for imposing data protection obligations on subprocessors and does not address liability issues. Additionally, it does not mention additional safeguards or compliance with standard contractual clauses for data transfers, nor does it address notification or consent for data transfers to new locations. Recommendations include revising these clauses to ensure compliance with GDPR guidelines.'\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "handler = workflow.run(contract_path=\"data/vendor_agreement.md\")\n",
        "async for event in handler.stream_events():\n",
        "    if isinstance(event, LogEvent):\n",
        "        if event.delta:\n",
        "            print(event.msg, end=\"\")\n",
        "        else:\n",
        "            print(event.msg)\n",
        "\n",
        "response_dict = await handler\n",
        "print(str(response_dict[\"report\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "bb0f5f52-ced9-49c2-82b9-131470fd291e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb0f5f52-ced9-49c2-82b9-131470fd291e",
        "outputId": "a9da9f88-6d73-4d28-fec2-376323a21dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vendor_name='ACME Office Supply, Inc.' overall_compliant=False summary_notes='The contract contains noncompliant clauses regarding subprocessors and data transfer mechanisms. It lacks provisions for imposing data protection obligations on subprocessors and does not address liability issues. Additionally, it does not mention additional safeguards or compliance with standard contractual clauses for data transfers, nor does it address notification or consent for data transfers to new locations. Recommendations include revising these clauses to ensure compliance with GDPR guidelines.'\n"
          ]
        }
      ],
      "source": [
        "print(str(response_dict[\"report\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "dda1efaa-f7cf-4a05-a2f7-13bcb15d26ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dda1efaa-f7cf-4a05-a2f7-13bcb15d26ef",
        "outputId": "f9ffb511-c2d5-4353-afdd-d30a87939761"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ClauseComplianceCheck(clause_text='- Vendor may engage subprocessors without prior Client approval - Subprocessors may be located in any jurisdiction globally - Notice of new subprocessors provided within 30 days of engagement - Client has no right to object to new subprocessors', matched_guideline=GuidelineMatch(guideline_text=\"Where a processor engages another processor for carrying out specific processing activities on behalf of the controller, the same data protection obligations as set out in the contract or other legal act between the controller and the processor as referred to in paragraph 3 shall be imposed on that other processor by way of a contract or other legal act under Union or Member State law, in particular providing sufficient guarantees to implement appropriate technical and organisational measures in such a manner that the processing will meet the requirements of this Regulation. Where that other processor fails to fulfil its data protection obligations, the initial processor shall remain fully liable to the controller for the performance of that other processor's obligations.\", similarity_score=0.85, relevance_explanation='The guideline emphasizes the need for data protection obligations to be imposed on subprocessors, which is relevant to the clause about engaging subprocessors.'), compliant=False, notes='The clause does not ensure that subprocessors will adhere to the same data protection obligations as required by the guideline. It lacks provisions for imposing data protection obligations on subprocessors and does not address liability issues.'),\n",
              " ClauseComplianceCheck(clause_text='- Vendor maintains primary data centers in the United States - Vendor may transfer data to any country where it maintains operations - No prior notification required for new data storage locations - Vendor will rely on its standard data transfer mechanisms - Data may be processed by staff operating outside the EEA', matched_guideline=GuidelineMatch(guideline_text='standard data-protection clauses in a wider contract, such as a contract between the processor and another processor , nor from adding other clauses or additional safe guards provided that they do not contradict, directly or indirectly , the standard contractual clauses adopted by the Commission or by a supervisory authority or prejudice the fundamental rights or freedoms of the data subjects. Controllers and processors should be encouraged to provide additional safeguards via contractual commitments that supplement standard protection clauses.', similarity_score=0.85, relevance_explanation=\"The guideline emphasizes the importance of standard data protection clauses and additional safeguards, which are relevant to the clause's mention of standard data transfer mechanisms.\"), compliant=False, notes='The clause lacks mention of additional safeguards or compliance with standard contractual clauses as recommended by the guideline. It also does not address the need for notification or consent for data transfers to new locations, which could be a compliance issue.')]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "response_dict[\"non_compliant_results\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "710ae172-b7e7-4d95-960f-f9cd90b40e3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "710ae172-b7e7-4d95-960f-f9cd90b40e3f",
        "outputId": "acd9dd06-7cc5-4905-9fac-32b43f914aef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'report': ComplianceReport(vendor_name='ACME Office Supply, Inc.', overall_compliant=False, summary_notes='The contract contains noncompliant clauses regarding subprocessors and data transfer mechanisms. It lacks provisions for imposing data protection obligations on subprocessors and does not address liability issues. Additionally, it does not mention additional safeguards or compliance with standard contractual clauses for data transfers, nor does it address notification or consent for data transfers to new locations. Recommendations include revising these clauses to ensure compliance with GDPR guidelines.'),\n",
              " 'non_compliant_results': [ClauseComplianceCheck(clause_text='- Vendor may engage subprocessors without prior Client approval - Subprocessors may be located in any jurisdiction globally - Notice of new subprocessors provided within 30 days of engagement - Client has no right to object to new subprocessors', matched_guideline=GuidelineMatch(guideline_text=\"Where a processor engages another processor for carrying out specific processing activities on behalf of the controller, the same data protection obligations as set out in the contract or other legal act between the controller and the processor as referred to in paragraph 3 shall be imposed on that other processor by way of a contract or other legal act under Union or Member State law, in particular providing sufficient guarantees to implement appropriate technical and organisational measures in such a manner that the processing will meet the requirements of this Regulation. Where that other processor fails to fulfil its data protection obligations, the initial processor shall remain fully liable to the controller for the performance of that other processor's obligations.\", similarity_score=0.85, relevance_explanation='The guideline emphasizes the need for data protection obligations to be imposed on subprocessors, which is relevant to the clause about engaging subprocessors.'), compliant=False, notes='The clause does not ensure that subprocessors will adhere to the same data protection obligations as required by the guideline. It lacks provisions for imposing data protection obligations on subprocessors and does not address liability issues.'),\n",
              "  ClauseComplianceCheck(clause_text='- Vendor maintains primary data centers in the United States - Vendor may transfer data to any country where it maintains operations - No prior notification required for new data storage locations - Vendor will rely on its standard data transfer mechanisms - Data may be processed by staff operating outside the EEA', matched_guideline=GuidelineMatch(guideline_text='standard data-protection clauses in a wider contract, such as a contract between the processor and another processor , nor from adding other clauses or additional safe guards provided that they do not contradict, directly or indirectly , the standard contractual clauses adopted by the Commission or by a supervisory authority or prejudice the fundamental rights or freedoms of the data subjects. Controllers and processors should be encouraged to provide additional safeguards via contractual commitments that supplement standard protection clauses.', similarity_score=0.85, relevance_explanation=\"The guideline emphasizes the importance of standard data protection clauses and additional safeguards, which are relevant to the clause's mention of standard data transfer mechanisms.\"), compliant=False, notes='The clause lacks mention of additional safeguards or compliance with standard contractual clauses as recommended by the guideline. It also does not address the need for notification or consent for data transfers to new locations, which could be a compliance issue.')]}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "response_dict"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llamacloud-demo",
      "language": "python",
      "name": "llamacloud-demo"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}